WEBVTT

1
00:00:01.450 --> 00:00:05.305
以下内容在CC协议下发布

2
00:00:05.310 --> 00:00:11.407
你的支持就是MIT OCW不断
提供高质量免费教学资源的动力

3
00:00:11.422 --> 00:00:12.615
如有意赞助MIT OCW

4
00:00:12.624 --> 00:00:16.021
或获取更多MIT成百上千的公开课资源

5
00:00:16.029 --> 00:00:21.005
请访问ocw.mit.edu

6
00:00:23.013 --> 00:00:26.667
欢迎来听MIT 6.172

7
00:00:26.771 --> 00:00:28.971
我叫Charles Leiserson

8
00:00:29.015 --> 00:00:32.069
这学期的两个讲师之一

9
00:00:32.102 --> 00:00:34.544
另一位是教授Julian Shun

10
00:00:35.015 --> 00:00:41.529
我们两都在威廉盖茨楼七层的EECS和CSAIL实验室中

11
00:00:43.869 --> 00:00:50.712
如果你还不清楚这里正要上软件系统性能调优

12
00:00:50.733 --> 00:00:55.507
不知道你可能跑错了地方, 那现在你该赶紧走了

13
00:00:57.029 --> 00:01:04.168
开始之前, 我想稍微谈谈为什么我们需要优化性能

14
00:01:04.723 --> 00:01:09.299
然后会说一下课程安排

15
00:01:09.321 --> 00:01:13.515
接着直接分析一个典型案例

16
00:01:13.536 --> 00:01:18.026
来让你感受一下我们这个学期要学什么

17
00:01:19.339 --> 00:01:20.993
我把课程安排放在中间讲

18
00:01:21.000 --> 00:01:25.325
因为有时候, 比如我和你讲了这门课程

19
00:01:25.358 --> 00:01:27.503
你却不想听这门课

20
00:01:27.526 --> 00:01:30.734
那.. 为什么你还要听课程安排呢, 对不对?

21
00:01:34.308 --> 00:01:37.010
所以让我们开始今天的课程吧?

22
00:01:37.010 --> 00:01:41.477
不管做什么, 你首先要明白一件事

23
00:01:41.500 --> 00:01:45.780
就是你到底在做什么

24
00:01:45.780 --> 00:01:49.511
整个学期, 我们都要学习如何优化性能

25
00:01:49.775 --> 00:01:52.590
这其实很有意思

26
00:01:52.590 --> 00:01:55.380
因为程序员在写软件的时候

27
00:01:55.380 --> 00:02:00.512
性能通常并不是最重要的事情

28
00:02:01.770 --> 00:02:04.487
什么事情比软件更重要呢?

29
00:02:04.587 --> 00:02:06.588
对不起, 我是说比性能

30
00:02:07.292 --> 00:02:08.029
答案?

31
00:02:08.051 --> 00:02:10.648
听众: 死线
CHARLES LEISERSON: 死线, 很好

32
00:02:10.659 --> 00:02:13.180
听众: 经费
CHARLES LEISERSON: 经费

33
00:02:13.180 --> 00:02:15.481
听众: 正确性
CHARLES LEISERSON: 正确性

34
00:02:15.481 --> 00:02:18.190
听众: 拓展性
CHARLES LEISERSON: 拓展性

35
00:02:18.190 --> 00:02:19.870
没错, 还有很多很多

36
00:02:19.870 --> 00:02:24.469
我觉得你们能列出一个非常长的清单

37
00:02:24.483 --> 00:02:30.003
我列了个短清单, 这是各种比性能更重要的东西

38
00:02:30.747 --> 00:02:36.663
如果程序员真的愿意牺牲性能来换这些性质

39
00:02:37.562 --> 00:02:40.499
我们为什么要研究性能?

40
00:02:40.681 --> 00:02:45.900
这有点矛盾, 让人很迷糊

41
00:02:45.900 --> 00:02:53.214
大部分人开发软件时
性能并不是他们最关心的事情

42
00:02:53.236 --> 00:02:55.627
为什么还要研究它呢?

43
00:02:56.448 --> 00:03:00.248
我觉得答案是这样的

44
00:03:00.248 --> 00:03:03.645
性能就像是编程中的"货币"

45
00:03:03.762 --> 00:03:08.294
你用性能来"购买"上面这些性质

46
00:03:08.294 --> 00:03:10.714
所以你可能会这样说:

47
00:03:10.722 --> 00:03:13.150
我想让这个软件写着容易点

48
00:03:13.150 --> 00:03:16.628
所以我愿意牺牲一些性能

49
00:03:16.639 --> 00:03:18.806
让编程变简单一点

50
00:03:18.817 --> 00:03:24.484
我愿意牺牲一些性能来让整个系统更安全

51
00:03:25.168 --> 00:03:28.737
所有这些性质都得从性能"预算"里扣

52
00:03:28.759 --> 00:03:34.496
而且如果性能太差, 你的软件就不好用了

53
00:03:35.154 --> 00:03:39.492
我和程序员聊天的时候, 我说...

54
00:03:39.492 --> 00:03:41.700
你懂的, 他们都会开玩笑: 哦, 性能

55
00:03:41.700 --> 00:03:42.765
你竟然优化性能?

56
00:03:42.765 --> 00:03:43.890
性能根本不重要

57
00:03:43.890 --> 00:03:45.094
我从来不考虑性能

58
00:03:45.105 --> 00:03:50.424
但当我和使用电脑的人谈起来的时候

59
00:03:50.435 --> 00:03:55.870
我问, 你对你电脑系统最大的不满是什么

60
00:03:55.889 --> 00:03:57.315
回答?

61
00:03:57.326 --> 00:03:58.653
太卡了

62
00:03:59.307 --> 00:04:02.465
所以不管你是写软件的, 还是什么人, 这个话题都很有趣

63
00:04:02.480 --> 00:04:07.083
但真正的重点是性能和钱类似

64
00:04:07.083 --> 00:04:08.649
你得花钱才能买到东西

65
00:04:08.749 --> 00:04:10.668
我更想要....

66
00:04:10.679 --> 00:04:16.641
你想像一下, 我在100美元和一桶水中要选哪一个?

67
00:04:17.657 --> 00:04:20.722
水是生命之源

68
00:04:20.733 --> 00:04:24.970
有些情况下我当然更需要水

69
00:04:25.819 --> 00:04:27.600
比起100美元来说

70
00:04:28.100 --> 00:04:35.010
但现今社会, 买一桶水根本花不了100美元

71
00:04:36.560 --> 00:04:40.760
所以即使水是生命之源

72
00:04:40.760 --> 00:04:45.500
比钱这种货币要重要的多

73
00:04:45.500 --> 00:04:49.694
我还是更喜欢钱, 因为我可以直接买我所想

74
00:04:49.730 --> 00:04:52.700
对于性能来说也是一样的道理

75
00:04:52.700 --> 00:04:58.500
它没有固有价值, 但是它能产生价值

76
00:04:58.500 --> 00:05:05.012
你可以用它来换可用性, 可测试性, 或者什么别的

77
00:05:06.218 --> 00:05:09.317
计算机发展早期阶段

78
00:05:09.318 --> 00:05:12.389
软件性能调优很常见

79
00:05:12.389 --> 00:05:14.540
因为机器资源机器有限

80
00:05:14.540 --> 00:05:20.337
你看看这些1964到1977年间的机器

81
00:05:20.720 --> 00:05:25.060
我是说, 看看他们的内存大小

82
00:05:25.060 --> 00:05:31.070
64年, 这台电脑只有524KB

83
00:05:31.741 --> 00:05:35.161
过去那可是台强大的机器

84
00:05:35.161 --> 00:05:38.888
但那个单位是千字节
不是MB, 不是GB, 是KB

85
00:05:39.771 --> 00:05:45.725
许多软件都会榨光所有的资源, OK?

86
00:05:46.414 --> 00:05:50.369
那台电脑的主频只有33KHz

87
00:05:50.391 --> 00:05:53.524
现在我们电脑的主频一般是多少?

88
00:05:53.524 --> 00:05:54.770
听众: 4GHz

89
00:05:54.770 --> 00:05:56.020
CHARLES LEISERSON: 差不多多少?

90
00:05:56.020 --> 00:05:56.480
听众: 4GHz

91
00:05:56.480 --> 00:05:59.270
CHARLES LEISERSON: 4GHz, 3 GHz, 2 GHz,

92
00:05:59.270 --> 00:06:00.080
差不多就这儿

93
00:06:00.080 --> 00:06:02.540
没错, 差不多就在这个区间里, OK?

94
00:06:02.551 --> 00:06:05.026
而这台机器主频是以KHz为单位的

95
00:06:05.081 --> 00:06:10.360
所以很多软件不优化性能根本无法运行

96
00:06:10.712 --> 00:06:17.556
而且那个时代, 也出了很多关于性能调优的名言

97
00:06:17.575 --> 00:06:27.037
Donald Knuth, 图灵奖得主, 计算机领域各方面都很优秀

98
00:06:27.072 --> 00:06:30.408
他写道: "盲目优化是万恶之源"

99
00:06:30.408 --> 00:06:32.990
另外我希望你能详细调查一下这句名言

100
00:06:32.998 --> 00:06:35.560
因为他是摘出来的, 脱离了原本的上下文

101
00:06:35.699 --> 00:06:38.670
所以他担心性能调优做的太早

102
00:06:40.200 --> 00:06:45.480
Bill Wulf, BLISS语言之父

103
00:06:45.480 --> 00:06:47.850
而且设计了PDP-11等等

104
00:06:47.850 --> 00:06:51.945
他说, "很多编程错误的根源是追求性能胜过一切

105
00:06:51.961 --> 00:06:57.040
甚至胜过盲目本身(而且还不一定真的提高了性能)"

106
00:06:58.441 --> 00:07:00.750
而Michael Jackson说过

107
00:07:00.750 --> 00:07:03.601
"软件调优的第一条原则: 不要做优化"

108
00:07:03.605 --> 00:07:08.783
"给专家们的第二条原则, 先别急着调优"

109
00:07:09.307 --> 00:07:11.499
所有人都在警告你不要着急

110
00:07:11.508 --> 00:07:15.760
因为你优化之后代码可读性就会变差

111
00:07:16.107 --> 00:07:19.170
让代码又快, 又容易看懂

112
00:07:19.170 --> 00:07:21.540
这是最有挑战性的地方

113
00:07:21.540 --> 00:07:23.720
希望我们多少能学到这一点

114
00:07:26.026 --> 00:07:35.005
而且很长一段时间内, 确实没有做优化的好理由

115
00:07:35.030 --> 00:07:37.390
请看这个工艺缩放图

116
00:07:37.390 --> 00:07:44.987
看看直到04年之前, 各种处理器上晶体管数量的增长趋势

117
00:07:45.432 --> 00:07:52.830
这段时间摩尔定律还是完全体

118
00:07:52.830 --> 00:07:57.560
每两年芯片密度就翻一倍

119
00:07:57.560 --> 00:08:00.766
相当惊人

120
00:08:00.788 --> 00:08:05.755
与此同时, 芯片尺寸不断缩小

121
00:08:05.790 --> 00:08:10.806
因为小型化也可以提升时钟频率

122
00:08:11.322 --> 00:08:14.837
所以如果你觉得什么东西跑得很慢

123
00:08:14.848 --> 00:08:16.900
等个几年不就好了?

124
00:08:17.624 --> 00:08:20.188
等上几年, 他就变快了

125
00:08:21.624 --> 00:08:27.368
所以比起做优化, 让你的代码变丑

126
00:08:27.530 --> 00:08:41.320
可能什么都不干, 等一等更实在一点

127
00:08:43.182 --> 00:08:47.022
那个时代有一个Dennard缩放定律

128
00:08:47.431 --> 00:08:56.839
如果缩小芯片尺寸, 就可以相应的提高时钟频率

129
00:08:56.870 --> 00:08:59.670
基本就是通过减小功耗实现

130
00:08:59.670 --> 00:09:02.135
你可以减小功耗, 而且运行速度还是一样快

131
00:09:02.135 --> 00:09:04.210
我们之后会稍微解释一下这个原理

132
00:09:04.221 --> 00:09:09.646
如果你看看1977到2004年的发展

133
00:09:09.657 --> 00:09:16.350
这些是标价的苹果电脑

134
00:09:16.350 --> 00:09:21.750
你能看到CPU主频火箭式飞升

135
00:09:21.750 --> 00:09:26.918
1 Mhz, 400 Mhz, 1.8 Ghz

136
00:09:26.929 --> 00:09:30.630
而数据总线从8bits, 升到32, 再到64

137
00:09:30.630 --> 00:09:32.880
内存大小也随之增长

138
00:09:32.880 --> 00:09:33.630
价钱?

139
00:09:33.641 --> 00:09:35.554
差不多一样

140
00:09:35.587 --> 00:09:42.941
这是摩尔定律和半导体工艺巨大进步留下的遗产

141
00:09:42.984 --> 00:09:50.443
所以, 直到2004年, 摩尔定律, 以及主频缩放定律
或者说Dennard缩放定律

142
00:09:50.469 --> 00:09:53.981
其实是在印发性能货币

143
00:09:54.340 --> 00:09:55.998
你什么都不用作

144
00:09:55.998 --> 00:09:57.540
只要让硬件跑的更快就好了

145
00:09:57.540 --> 00:09:59.820
非常简单

146
00:09:59.820 --> 00:10:03.221
但是这一切都结束了

147
00:10:03.231 --> 00:10:05.130
至少有一部分结束了

148
00:10:05.141 --> 00:10:09.378
2004年, 主频到达瓶颈了

149
00:10:09.703 --> 00:10:12.570
所以你看到2005年

150
00:10:12.570 --> 00:10:17.897
主频差不多就在2到4Ghz之间

151
00:10:18.030 --> 00:10:24.705
从此之后, 芯片主频再也没有什么实质上的提升

152
00:10:24.763 --> 00:10:26.880
但是密度仍然持续增高

153
00:10:26.880 --> 00:10:32.360
主频提升缓慢的原因是电源密度

154
00:10:32.430 --> 00:10:37.050
这是Intel当时的演示页面

155
00:10:37.050 --> 00:10:41.396
看看电源密度的走势, 还有他们的横轴

156
00:10:41.400 --> 00:10:46.500
代表着芯片晶体管连接点的温度

157
00:10:46.500 --> 00:10:51.612
如果一直和之前一样缩放

158
00:10:51.637 --> 00:10:57.000
温度首先会变的像核反应一样高

159
00:10:57.000 --> 00:11:00.209
然后会像火箭喷口一样, 最后会像太阳表面一样热

160
00:11:00.610 --> 00:11:04.781
我们做不出小型高效的制冷设备

161
00:11:04.924 --> 00:11:08.456
就算你能够稍微解决制冷问题, 也还有更困难的事情

162
00:11:08.520 --> 00:11:11.269
我们还是不能再继续缩放时钟频率

163
00:11:11.280 --> 00:11:14.070
因为, 原本缩放时钟频率的时候

164
00:11:14.070 --> 00:11:18.980
我们假设大部分电能是动态电能

165
00:11:19.005 --> 00:11:21.673
就是你电路开合时产生的电能

166
00:11:21.695 --> 00:11:24.420
当我们持续削减电源之后

167
00:11:24.420 --> 00:11:31.458
曾经是噪音, 也就是泄露电流变的重要起来

168
00:11:31.503 --> 00:11:43.260
因为现今动态电能比电路泄露的静态电能还要小

169
00:11:43.290 --> 00:11:49.122
小型化芯片时, 这个效应根本无法避免

170
00:11:49.440 --> 00:11:54.090
所以04, 05年的厂商们做了什么呢?

171
00:11:54.090 --> 00:12:00.779
他们一拍脑门: 天啊, 我们有这么多晶体管

172
00:12:00.780 --> 00:12:06.000
但是我们却不能用这些晶体管让芯片跑得更快

173
00:12:06.000 --> 00:12:11.019
所以他们引入了并行, 也就是多核处理器

174
00:12:11.070 --> 00:12:14.170
他们在芯片上放了不止一个计算核心

175
00:12:14.181 --> 00:12:19.380
为了继续提高性能, 你就有了很多核心

176
00:12:19.380 --> 00:12:27.826
而摩尔定律现在变成了每年核心数量翻倍

177
00:12:27.900 --> 00:12:31.590
你可以看看处理器核心数量的变化

178
00:12:31.590 --> 00:12:40.195
从2004,2005年左右, 开始出现多核处理器

179
00:12:40.236 --> 00:12:48.692
到现在, 你在笔记本, 工作站或者什么东西上, 根本找不到单核芯片

180
00:12:48.723 --> 00:12:50.601
所有东西都是多核的

181
00:12:50.601 --> 00:12:52.415
你买不到单核芯片

182
00:12:52.437 --> 00:12:54.150
你只能买到并行处理器

183
00:12:59.222 --> 00:13:03.523
这种情况的后果是, 性能提升不再廉价

184
00:13:03.540 --> 00:13:05.629
你不能单单提升硬件性能

185
00:13:05.640 --> 00:13:08.400
如果你想利用硬件的全部性能

186
00:13:08.400 --> 00:13:09.882
你就不得不并行编程

187
00:13:09.882 --> 00:13:14.839
以前工业业界上从来没有人做过这些事情

188
00:13:15.514 --> 00:13:20.049
所以那段时间发生了很多变革

189
00:13:20.067 --> 00:13:23.910
向量计算单元广泛出现在机器上;

190
00:13:23.910 --> 00:13:28.416
出现了GPU; 处理器的缓存层级变得更复杂;

191
00:13:28.920 --> 00:13:32.877
某些机器还有可配置的逻辑电路; 等等

192
00:13:32.877 --> 00:13:36.016
现在是软件的责任来来适应硬件了

193
00:13:36.027 --> 00:13:40.547
所以, 尽管我们不想做性能调优

194
00:13:40.558 --> 00:13:43.080
现在你不得不去优化性能了

195
00:13:43.080 --> 00:13:49.639
所以你后半生都需要去优化性能,
如果你想要做出好用的软件的话

196
00:13:52.097 --> 00:13:53.828
你能看出这方面的趋势

197
00:13:53.836 --> 00:14:05.283
我们统计了提到"性能"这个词的各类开源项目的软件bug

198
00:14:05.311 --> 00:14:09.725
你可以看到2004年左右开始上升

199
00:14:09.725 --> 00:14:14.330
额, 虽然其中某些并不和其他的一样明显

200
00:14:14.351 --> 00:14:18.360
但2004年左右有这样上升的趋势

201
00:14:18.360 --> 00:14:20.798
人们开始关注性能问题

202
00:14:20.820 --> 00:14:23.707
如果你调研软件开发工作

203
00:14:25.349 --> 00:14:34.496
差不多在2000年左右的时候

204
00:14:34.530 --> 00:14:39.025
你可以看到提到"性能"的工作数量也在上升

205
00:14:39.240 --> 00:14:48.565
其实, 我有个学生春假之后, 上了6.172之后, 来找我

206
00:14:48.580 --> 00:14:54.886
他说, 我去应聘了五份工作

207
00:14:54.990 --> 00:15:00.160
每份工作, 每场面试, 他们都问了一些难问题

208
00:15:00.176 --> 00:15:03.510
没听过6.172的话, 我不可能答上来

209
00:15:03.526 --> 00:15:06.000
最后我拿了五个offer

210
00:15:06.540 --> 00:15:08.340
当我比较这些offer的时候, 我发现

211
00:15:08.340 --> 00:15:13.534
他们薪资比web码农要高20%到30%

212
00:15:15.070 --> 00:15:16.082
所以不管怎么说

213
00:15:16.099 --> 00:15:21.541
我并没有说你必须要听这门课

214
00:15:21.571 --> 00:15:28.844
我只是想指出我们要学的东西很有现实意义

215
00:15:28.900 --> 00:15:30.720
就是你的未来

216
00:15:31.185 --> 00:15:34.879
当然也包括理论角度, 以及技术角度

217
00:15:36.348 --> 00:15:48.298
所以现代处理器很复杂, 问题是我们怎么高效利用现代硬件

218
00:15:49.482 --> 00:15:53.040
我想展示一个性能调优的案例

219
00:15:53.040 --> 00:15:57.765
一个研究的很透彻的问题, 叫做矩阵乘法

220
00:15:58.148 --> 00:16:01.079
有人没见过这个问题的吗?

221
00:16:01.079 --> 00:16:04.173
听众: 有

222
00:16:04.184 --> 00:16:07.700
看来有些"幽默大师", 可以理解

223
00:16:10.011 --> 00:16:14.477
所以你知道的, 总共需要n的立方次运算

224
00:16:14.477 --> 00:16:17.757
因为你做了n的平方次点积

225
00:16:18.600 --> 00:16:22.710
不过如果你把所有操作数都加起来的话

226
00:16:22.710 --> 00:16:25.950
应该是2n^3个运算操作

227
00:16:25.950 --> 00:16:29.790
因为每次计算都需要一次乘法和一次加法

228
00:16:29.790 --> 00:16:32.020
这样才能累积结果

229
00:16:32.290 --> 00:16:34.193
所以应该是2n的立方次运算

230
00:16:34.193 --> 00:16:40.944
我们为了简便, 就假设n正好是2的幂

231
00:16:42.068 --> 00:16:51.637
然后, 我们要使用的机器你可以在AWS上接触到

232
00:16:52.187 --> 00:16:57.120
这是台专为计算服务的机器

233
00:16:57.120 --> 00:17:02.675
CPU为Haswell架构, 主频2.9Ghz

234
00:17:02.830 --> 00:17:14.013
每台机器有两个CPU, 每个处理器有9个处理核心, 共18核

235
00:17:14.490 --> 00:17:17.160
这是总的并行数

236
00:17:17.160 --> 00:17:24.776
虽然他有超线程技术, 但我们并不准备用

237
00:17:24.819 --> 00:17:30.758
超线程可以略微提高性能, 但也让测量变得更困难了

238
00:17:30.930 --> 00:17:33.524
所以我们一般会关闭超线程

239
00:17:33.540 --> 00:17:40.103
不过你测得的性能和超线程开启之后的应该是正相关的

240
00:17:40.142 --> 00:17:46.066
浮点方面, 每个核心, 每个时钟周期, 你都有八个双精度浮点运算单元

241
00:17:46.114 --> 00:17:54.022
也就是64bit精度浮点运算, 支持乘加融合为单指令

242
00:17:55.250 --> 00:17:56.540
所以这是个向量计算单元

243
00:17:56.540 --> 00:18:02.907
基本上18核, 每个核都能做8个双精度运算

244
00:18:03.163 --> 00:18:07.966
包括乘加融合运算, 那实际上是两个运算的结合

245
00:18:08.323 --> 00:18:11.220
这是浮点运算量的计算方式

246
00:18:11.570 --> 00:18:19.344
它的缓存线长度为64B, 指令缓存为8路32KB

247
00:18:19.377 --> 00:18:22.807
我们之后会说这些, 你不了解这些术语, 没有关系

248
00:18:22.940 --> 00:18:25.710
之后我们会讲到这些东西

249
00:18:25.731 --> 00:18:28.121
它的数据缓存也是同样大小

250
00:18:28.154 --> 00:18:32.612
它的二级缓存有256KB

251
00:18:32.722 --> 00:18:40.095
25MB三级缓存, 或者说最后一级缓存, 简写LLC

252
00:18:40.171 --> 00:18:43.200
以及60GB的DRAM

253
00:18:43.364 --> 00:18:49.201
这是台大型机器, 差不多什么东西都能在上面跑

254
00:18:49.553 --> 00:18:52.330
接下来关注一下峰值性能

255
00:18:52.330 --> 00:18:56.890
主频乘以两个处理器

256
00:18:56.890 --> 00:19:05.140
再乘以每个处理器的9个核心

257
00:19:05.140 --> 00:19:12.972
以及每个核心可用的乘加共16次浮点运算

258
00:19:13.938 --> 00:19:19.644
差不多有1TFlops, 836GFlops

259
00:19:20.090 --> 00:19:22.933
这很强大, 对吧?

260
00:19:22.933 --> 00:19:23.850
真的很强大

261
00:19:23.850 --> 00:19:32.423
其实这些机器很有趣, 尤其是去做游戏AI的时候

262
00:19:32.459 --> 00:19:34.705
或者第四个项目那样的东西, 你会明白的

263
00:19:34.730 --> 00:19:37.548
真的很有意思, 你可以做大量计算

264
00:19:38.746 --> 00:19:41.250
这是最原始的代码

265
00:19:41.250 --> 00:19:45.211
这是用来做矩阵计算的全部python代码

266
00:19:45.240 --> 00:19:48.690
不过,  一般来说, 你不会这样写python

267
00:19:48.690 --> 00:19:54.536
你会调库来做矩阵计算, 但有些时候会有问题

268
00:19:54.545 --> 00:20:02.531
我想用矩阵计算来展示这些问题, 所以必须亲自写计算代码

269
00:20:02.910 --> 00:20:08.135
我想让你感受python的性能如何

270
00:20:08.400 --> 00:20:13.788
而且, 如果需要一个矩阵计算的库, 那必须得有人来写

271
00:20:13.851 --> 00:20:16.200
而那个人肯定是个性能调优师

272
00:20:16.200 --> 00:20:18.400
因为他写的程序必须越快越好

273
00:20:18.400 --> 00:20:23.015
所以接下来我们就来看看怎么让代码跑得更快

274
00:20:23.190 --> 00:20:26.985
所以你可以看到, 运行代码时, 在三层循环前会保存开始时间

275
00:20:27.006 --> 00:20:31.050
就是这个三层循环前面这行

276
00:20:31.050 --> 00:20:34.140
刚好在三层循环前的这个

277
00:20:34.140 --> 00:20:37.945
我们记录一下时间, 然后结束的时候再记录一次

278
00:20:37.950 --> 00:20:46.215
然后我们打印两时间之差, 就是这个三层循环矩阵计算花费的时间

279
00:20:47.474 --> 00:20:50.836
所以, 猜猜看这段代码会运行多长时间?

280
00:20:55.380 --> 00:20:57.800
有想法吗?

281
00:20:57.800 --> 00:21:00.223
我想想, 这么来吧

282
00:21:00.560 --> 00:21:05.151
它运行了6微秒, 谁觉得是6微妙?

283
00:21:05.392 --> 00:21:10.863
6毫秒又如何呢, 6毫秒?

284
00:21:11.585 --> 00:21:12.947
那么6秒呢?

285
00:21:16.506 --> 00:21:18.201
那有没有支持6分钟的人?

286
00:21:20.666 --> 00:21:22.926
整整6个小时呢?

287
00:21:24.464 --> 00:21:26.643
或者整整6天?

288
00:21:28.897 --> 00:21:30.980
当然, 矩阵大小很重要

289
00:21:30.980 --> 00:21:35.777
如代码所示, 矩阵大小是4096 * 4096

290
00:21:36.035 --> 00:21:41.114
还有没投票的人, 醒一醒, 精神点儿

291
00:21:41.190 --> 00:21:44.189
这场学习是互动的, 让你自己参与进来

292
00:21:44.265 --> 00:21:45.850
对错并不重要

293
00:21:45.850 --> 00:21:49.732
有很多人都答对了, 但他们根本不知道为什么

294
00:21:51.222 --> 00:21:58.240
结果是它花费了21000秒, 差不多6小时

295
00:21:59.470 --> 00:22:01.312
太惊人了, 这很快吗?

296
00:22:02.437 --> 00:22:04.313
听众: (讽刺) 快

297
00:22:04.918 --> 00:22:06.210
CHARLES LEISERSON: 好吧

298
00:22:07.795 --> 00:22:08.893
这很快吗? 并不

299
00:22:08.980 --> 00:22:15.550
我们怎么衡量他是慢还是快

300
00:22:16.020 --> 00:22:18.493
就是说我们期望的机器执行情况是怎样的?

301
00:22:18.493 --> 00:22:21.223
让我们做个粗略计算

302
00:22:24.242 --> 00:22:28.333
算算我们有多少运算, 以及机器应该能跑到多块

303
00:22:28.340 --> 00:22:31.088
刚刚我们说了机器所有的参数

304
00:22:31.760 --> 00:22:35.130
而且总运算量为2n的立方次

305
00:22:35.130 --> 00:22:37.617
没有应用Strassen算法或者别的什么

306
00:22:37.630 --> 00:22:42.470
我们只是做了一个简单的三层循环

307
00:22:42.470 --> 00:22:50.964
所以一共2^37次运算, 耗时21000秒

308
00:22:51.712 --> 00:23:00.528
也就是说代码的运算速度差不多是6.25MFlops

309
00:23:01.064 --> 00:23:05.982
这是用运算量除以时间得到的结果

310
00:23:06.020 --> 00:23:11.780
运算次数除以耗时得到运算速度, 懂吗?

311
00:23:11.780 --> 00:23:17.037
机器峰值, 如果你还记得, 是856GFlops

312
00:23:17.043 --> 00:23:22.091
而我们的运算速度是6.25MFlops

313
00:23:22.715 --> 00:23:37.488
大概是峰值的0.00075%, 这一点都不快

314
00:23:38.241 --> 00:23:39.978
这很慢

315
00:23:42.476 --> 00:23:45.330
让我们做点简单的改进

316
00:23:45.330 --> 00:23:49.406
我们用java而不是python来写同样的代码

317
00:23:49.537 --> 00:23:51.720
所以还是那个循环

318
00:23:51.720 --> 00:23:55.462
代码几乎一样, 就是这个三层循环

319
00:23:55.470 --> 00:23:57.937
但是是用java来跑

320
00:23:58.047 --> 00:24:07.002
而运行时间差不多小3000秒, 约46分钟

321
00:24:08.498 --> 00:24:13.524
同样的代码, 只是语言不同, python, java

322
00:24:13.528 --> 00:24:22.493
我们得到了大约九倍的性能提升, 只是换了个语言

323
00:24:23.928 --> 00:24:28.287
再让我们试试C语言, 这堂课会用C语言来讲

324
00:24:28.293 --> 00:24:30.430
如果用C语言来写会怎样?

325
00:24:30.430 --> 00:24:36.506
依然是同样的操作, 使用clang/llvm 5.0编译

326
00:24:36.987 --> 00:24:40.560
不过这学期我们应该是要用clang/llvm 6.0

327
00:24:40.998 --> 00:24:45.694
我本来应该用6.0重新跑一遍这个测试的

328
00:24:45.705 --> 00:24:50.370
所以, 耗时约1100秒, 差不多19分钟

329
00:24:50.684 --> 00:24:57.508
比JAVA快一倍, 是python速度的18倍

330
00:24:58.120 --> 00:25:03.522
这是目前为止我们的成果, 各种方法的运行时间

331
00:25:04.576 --> 00:25:09.550
相对性能提升(relative speedup)是和上一行做比较

332
00:25:09.561 --> 00:25:13.837
绝对性能提升(absolute speedup)是和第一行做比较

333
00:25:13.860 --> 00:25:21.956
我们现在最好的成绩是峰值的0.014%

334
00:25:21.996 --> 00:25:29.513
所以还是很慢, 不过在继续优化之前

335
00:25:29.854 --> 00:25:33.740
为什么python这么慢, 而C语言这么快呢?

336
00:25:33.740 --> 00:25:36.880
有人知道吗?

337
00:25:36.880 --> 00:25:39.244
听众: python是解释型语言

338
00:25:39.290 --> 00:25:43.639
所以有个C程序一直在解析python代码, 耗费大部分时间

339
00:25:45.463 --> 00:25:49.867
CHARLES LEISERSON: 没错. 这个思路是正确的

340
00:25:50.062 --> 00:25:55.506
还有人解释一下为什么python很慢吗?

341
00:25:55.830 --> 00:25:56.663
请答?

342
00:25:56.663 --> 00:25:58.830
听众: 虽然你只写了乘法和加法

343
00:25:58.830 --> 00:26:00.980
但这并不是python唯一在做的事情

344
00:26:00.980 --> 00:26:05.999
它做了很多, 比如解析python对象, 整数, 等等

345
00:26:06.254 --> 00:26:09.484
CHARLES LEISERSON: 对, 对, 非常好

346
00:26:09.819 --> 00:26:14.060
所以python比C语言慢的大致原因是

347
00:26:14.060 --> 00:26:20.667
python是解释型语言, c语言却会直接编译成机器语言

348
00:26:21.443 --> 00:26:23.240
java则是两者折中

349
00:26:23.240 --> 00:26:30.376
java首先编译成字节码, 随后使用JIT(即时编译)编译成机器语言

350
00:26:30.440 --> 00:26:33.920
让我稍微想一下该怎么表述

351
00:26:33.941 --> 00:26:39.995
所以解释型语言, 像python, 灵活多变但是慢

352
00:26:42.352 --> 00:26:49.290
这是"我们要牺牲性能, 提高灵活性, 降低编程难度"的案例之一

353
00:26:50.389 --> 00:26:57.497
解释器基本就是在读取, 解释, 运行每一行程序语句, 维护解释器状态

354
00:26:57.770 --> 00:27:06.727
所以它并不是... 它其实会读入代码, 搞清楚程序在做什么, 然后才跑起来

355
00:27:06.736 --> 00:27:12.000
除了运算本身, 还包括所有这些额外开销

356
00:27:12.325 --> 00:27:18.197
因为解释器可以动态解释代码, 所以解释语言很容易在高层次上编程

357
00:27:18.200 --> 00:27:21.097
当然是以性能为代价的

358
00:27:21.108 --> 00:27:24.590
一个解释器的循环通常和图上一样

359
00:27:24.590 --> 00:27:28.070
读取下一条指令, 解释下一条指令

360
00:27:28.070 --> 00:27:31.691
执行下一条指令, 更新解释器状态

361
00:27:31.775 --> 00:27:34.590
然后又开始读取下一个指令

362
00:27:35.090 --> 00:27:38.621
每一次你都在重复这个流程, 而且是用软件

363
00:27:39.860 --> 00:27:48.593
如果你编译成机器语言, 虽然运行过程相似, 但却是为机器量身定造的

364
00:27:49.593 --> 00:27:55.931
编译可以发挥硬件的优势, 利用硬件指令

365
00:27:55.972 --> 00:28:02.138
而且硬件上的额外开销非常小, 比python小得多

366
00:28:02.169 --> 00:28:05.593
java使用的JIT技术是个折中方案

367
00:28:06.042 --> 00:28:08.125
JIT编译器可以争取一些性能

368
00:28:08.125 --> 00:28:10.780
当前案例下, 它其实做的很不错

369
00:28:11.360 --> 00:28:15.704
JIT编译器大致是这样的, 刚开始执行的时候是解释执行

370
00:28:15.727 --> 00:28:22.932
然后动态追踪各部分代码执行的频繁程度

371
00:28:22.949 --> 00:28:27.233
如果它发现有一部分代码执行很频繁

372
00:28:27.305 --> 00:28:33.999
它就调用编译器编译那份代码, 然后把它为编译后的代码

373
00:28:34.104 --> 00:28:42.979
所以它试着只编译那些真正需要编译的代码来提高性能

374
00:28:42.999 --> 00:28:48.716
你懂的, 就是那些值得花额外算力去编译的代码

375
00:28:52.665 --> 00:28:57.112
这些语言的巨大差异大概就是这样

376
00:28:57.140 --> 00:28:59.870
这门课不使用python的理由很简单

377
00:28:59.870 --> 00:29:05.460
我们很难对它的性能进行良好的建模

378
00:29:05.960 --> 00:29:16.500
C语言更接近电路, 更接近半导体, 所以更容易明白到底发生了什么

379
00:29:18.471 --> 00:29:25.941
不过我们会有一次外援授课, 谈一谈python这样的高级语言的性能

380
00:29:25.975 --> 00:29:28.280
并不是说要忽视这个话题

381
00:29:28.280 --> 00:29:34.482
但我们还是选择用比较简单的途径来学习如何做性能调优

382
00:29:35.992 --> 00:29:43.631
优秀的编译器会做一些事, 比如, 一旦你...

383
00:29:43.970 --> 00:29:47.278
就以C语言为例, 接下来会从这个版本开始改进

384
00:29:47.298 --> 00:29:50.414
因为这是目前为止最快的版本

385
00:29:50.425 --> 00:29:56.836
分析表明改变循环的顺序并不影响结果的正确性

386
00:29:56.966 --> 00:30:01.512
当前, 我们先循环i, 再循环j, 最后是k

387
00:30:02.178 --> 00:30:07.507
我们也可以先循环i, 再循环k, 最后循环j

388
00:30:07.524 --> 00:30:10.507
结果是完全相同的

389
00:30:10.524 --> 00:30:16.550
当然可以先循环k, 再循环j, 最后循环i

390
00:30:17.237 --> 00:30:21.543
所以改变循环顺序不影响正确性

391
00:30:22.469 --> 00:30:29.639
你们觉得改变循环顺序会影响性能吗?

392
00:30:30.665 --> 00:30:32.540
这是最大的问题

393
00:30:32.540 --> 00:30:33.462
有问题吗?

394
00:30:33.480 --> 00:30:36.960
听众: 也许会影响缓存局部性

395
00:30:36.960 --> 00:30:38.270
CHARLES LEISERSON: 没错

396
00:30:38.299 --> 00:30:40.885
完全正确, 就是缓存局部性

397
00:30:40.910 --> 00:30:48.485
所以我们改变循环顺序, 可以得到18倍的速度提升

398
00:30:49.540 --> 00:30:52.063
哇哦, 只是改改顺序

399
00:30:53.225 --> 00:30:54.920
发生什么了?

400
00:30:55.760 --> 00:30:57.410
到底怎么回事?

401
00:30:57.410 --> 00:31:01.179
之后我们会详细解释这个话题, 现在就只大概解释一下

402
00:31:01.194 --> 00:31:05.009
只是让你明白为什么

403
00:31:05.043 --> 00:31:12.504
我们把硬件读写主内存得到的连续区块叫做缓存线

404
00:31:13.640 --> 00:31:19.285
以前访问过得缓存线都会存在一小块叫做 缓存 的, 就靠在处理器旁边的内存中

405
00:31:19.310 --> 00:31:24.218
当处理器访问什么东西的时候, 如果缓存里有, 也就是缓存命中了

406
00:31:24.230 --> 00:31:27.380
这很高效, 非常快

407
00:31:27.380 --> 00:31:32.465
如果未命中, 你就需要到下一级缓存访问, 或者直到访问主内存为止

408
00:31:32.515 --> 00:31:37.002
那就非常, 非常慢了, 我们之后会谈这件事

409
00:31:37.136 --> 00:31:45.254
对于这个矩阵计算问题, 矩阵在内存中是行优先存储的

410
00:31:45.274 --> 00:31:51.892
就是说, 如果你有一个二维矩阵, 它在内存中是线性排列的

411
00:31:51.900 --> 00:31:59.917
先存储行1. 接着是行2, 然后行3, 依次类推来展开矩阵

412
00:31:59.917 --> 00:32:06.497
还有一种可能的排列顺序, 实际上在fortran中, 就是列优先存储

413
00:32:06.996 --> 00:32:11.220
所以C语言和fortran的操作顺序是不同的

414
00:32:11.611 --> 00:32:14.219
而且这个顺序还会影响性能, 就像现在一样

415
00:32:14.582 --> 00:32:19.002
让我们先看砍以i, j, k顺序循环的情况

416
00:32:20.312 --> 00:32:27.704
程序是这样的, 一旦我们确定了i和j, 我们就要开始循环k

417
00:32:27.740 --> 00:32:33.491
当开始循环k的时候, C[i][j]一直不变

418
00:32:33.572 --> 00:32:38.606
空间局部性非常好, 因为每次都在访问同一位置

419
00:32:38.643 --> 00:32:41.746
每次都是缓存的, 它永远在那个地方

420
00:32:41.798 --> 00:32:44.300
所以访问C非常快

421
00:32:44.300 --> 00:32:50.462
对于A来说, 我们是线性顺序访问的, 空间局部性也很好

422
00:32:50.510 --> 00:32:53.330
但对于B来说, 我们是以列为准顺序访问的

423
00:32:53.330 --> 00:32:57.260
而这些位置在内存中的相距甚远

424
00:32:57.260 --> 00:33:02.673
所以处理器会读取64B, 却只取一小部分用

425
00:33:03.653 --> 00:33:13.337
那条缓存线上的8个浮点数中有7个无用, 下一条缓存线也是如此

426
00:33:13.376 --> 00:33:15.710
太浪费了, 不是吗?

427
00:33:15.710 --> 00:33:22.434
所以对于A空间局部性很好, 访问都是相邻的, 充分利用了局部性

428
00:33:22.465 --> 00:33:29.036
而对于B, 4096个元素全是隔开的, 空间局部性非常差

429
00:33:30.007 --> 00:33:36.965
这个循环顺序就是这样
我们还能看看i, k, j顺序的循环

430
00:33:37.069 --> 00:33:43.479
结果表明, C和B的空间局部性都不错, 而A非常好

431
00:33:43.960 --> 00:33:49.040
如果你看看另一个, 那个完全不如其他顺序好的那个

432
00:33:49.060 --> 00:33:50.665
它访问的范围太广了

433
00:33:50.689 --> 00:33:54.612
这个顺序下, C和A的空间局部性都很差

434
00:33:54.612 --> 00:34:04.242
所以你能直接测试一下不同顺序的缓存命中率, 可以使用一个工具来帮你测

435
00:34:04.266 --> 00:34:13.124
我们用的工具叫做Cachegrind, 是Valgrind缓存工具中的一个

436
00:34:13.156 --> 00:34:17.662
它会统计不同程序的缓存未命中率

437
00:34:17.918 --> 00:34:20.710
你将学习使用这个工具, 然后观察结果:

438
00:34:20.710 --> 00:34:24.140
哦! 看来有些未命中率很高, 其他的却很低

439
00:34:24.149 --> 00:34:28.075
也许这就是我程序运行慢的原因吧

440
00:34:28.075 --> 00:34:36.252
然后拿出最好的结果对比一下, 我们得到了6.5倍相对性能提升

441
00:34:36.414 --> 00:34:38.800
我们还可以尝试什么改动呢?

442
00:34:38.800 --> 00:34:45.083
其实有很多事情可以做, 有些甚至不需要改动代码

443
00:34:46.231 --> 00:34:49.989
还有什么能做的, 有玩过编译器的人吗?

444
00:34:50.515 --> 00:34:52.044
疯狂暗示

445
00:34:54.035 --> 00:34:54.569
请说

446
00:34:54.733 --> 00:34:56.650
听众: 你可以改编译器参数

447
00:34:56.650 --> 00:34:59.530
CHARLES LEISERSON: 对, 修改编译器参数

448
00:34:59.530 --> 00:35:05.368
所以Clang, 我们在用的编译器, 提供了一系列优化开关

449
00:35:05.395 --> 00:35:10.269
你可以传给编译器一个参数, 要求它优化代码

450
00:35:10.290 --> 00:35:14.080
传给它-O, 跟上一个数字

451
00:35:14.080 --> 00:35:18.178
如果数字是0, 你能从文档了解到是"不做任何优化"

452
00:35:18.191 --> 00:35:24.745
而1则是"优化", 2是"加大力度优化", 3是"最大力度优化"

453
00:35:25.566 --> 00:35:33.049
不过当前案例中, 最大优化力度的O3更慢, O2似乎才是最好的配置

454
00:35:34.430 --> 00:35:37.004
这是一次个例, 不总是这样

455
00:35:37.010 --> 00:35:42.878
一般来说O3都比O2快, 不过当前案例O2实际比O3优化更好

456
00:35:42.910 --> 00:35:46.520
因为优化其实是有些启发式的

457
00:35:47.180 --> 00:35:53.724
也有其他种类的优化, 比如profile导向优化

458
00:35:53.740 --> 00:36:03.807
你先收集运行情况的资料, 再反馈到代码上, 编译器就知道该怎么优化了

459
00:36:03.809 --> 00:36:11.970
还有许多别的优化, 所以只要选一个合适的优化参数

460
00:36:11.979 --> 00:36:18.984
当前案例为O2, 我们什么都没做就提升了3.25倍(相对性能)

461
00:36:20.116 --> 00:36:29.496
基本什么都没干, 对吧, 现在我们接近了峰值性能的1%

462
00:36:29.510 --> 00:36:32.607
现在是峰值性能的0.3%

463
00:36:33.297 --> 00:36:39.406
所以为什么性能这么差, 为什么没有利用上机器的大部分算力?

464
00:36:39.856 --> 00:36:41.505
你觉得呢?请说

465
00:36:41.700 --> 00:36:43.500
听众: 我们没有用上所有核心

466
00:36:43.500 --> 00:36:44.730
CHARLES LEISERSON: 正解, 我们没有用上所有核心

467
00:36:44.730 --> 00:36:48.007
目前为止只用了一个, 我们总共有多少个?

468
00:36:48.582 --> 00:36:49.530
听众: 18个

469
00:36:49.618 --> 00:36:52.220
CHARLES LEISERSON: 18个, 对吗?

470
00:36:52.220 --> 00:36:54.088
18个核心, 天啊!

471
00:36:54.387 --> 00:37:01.028
总共18个核心, 我们只给一个核心做优化, 其余17个都无所事事

472
00:37:02.230 --> 00:37:09.946
所以多核, 我们每个芯片有九个核, 机器一共两个芯片

473
00:37:10.236 --> 00:37:13.842
程序只跑在单核上, 让我们试试多核

474
00:37:13.864 --> 00:37:18.993
我们需要使用一个叫cilk的库

475
00:37:19.004 --> 00:37:27.546
使用其中一个叫做并行循环的东西, 叫做cilk_for

476
00:37:27.686 --> 00:37:30.720
所以你只要稍微改一下外层循环

477
00:37:30.720 --> 00:37:35.410
你说, cilk_for, 并行运算这个循环

478
00:37:35.473 --> 00:37:41.313
让编译器和运行时系统去做分配规划, 等等

479
00:37:41.944 --> 00:37:47.176
我们也可以改动内层循环

480
00:37:47.198 --> 00:37:54.864
不过如果你仔细想一想, 你会发现你不能修改中间的循环

481
00:37:55.500 --> 00:38:02.866
这个就当作是一个小作业, 为什么不能改动中间的循环?

482
00:38:03.997 --> 00:38:07.255
现在的问题是, 怎样并行循环最快?

483
00:38:07.266 --> 00:38:13.228
我们可以并行i循环, 也可以并行j循环, 或者两个都做

484
00:38:13.250 --> 00:38:19.234
但是如果让k并行循环, 结果就会出错, 这是一点

485
00:38:19.302 --> 00:38:25.022
所以如果你观察一下, 哇哦! 运行时间缩短太多了

486
00:38:25.446 --> 00:38:30.487
如果只并行i循环, 只耗时3.18s

487
00:38:30.487 --> 00:38:36.081
如果并行j循环, 我觉得, 应该是比原来更慢了?

488
00:38:37.630 --> 00:38:42.532
如果同时并行i和j, 结果还是比较慢, 还是只并行外层循环比较好

489
00:38:42.562 --> 00:38:48.985
这和并行规划的额外运算有关, 我们之后会教你如何判断这些

490
00:38:49.002 --> 00:38:53.499
所以经验教训就是, 并行外层而不是内层循环

491
00:38:53.518 --> 00:38:59.126
如果我们并行循环, 我们用18核得到几乎18倍的提升

492
00:38:59.685 --> 00:39:04.465
还有一件事, 不是所有代码都能这样轻易的并行化

493
00:39:05.285 --> 00:39:12.318
但这个可以, 所以现在, 大约是峰值的5%

494
00:39:13.650 --> 00:39:21.486
所以为什么还是慢? 为什么只有5%?
请说?

495
00:39:21.486 --> 00:39:28.021
听众: 还可以做其他的并行化

496
00:39:28.409 --> 00:39:31.882
我们可以, 比如说, 向量化乘法

497
00:39:31.882 --> 00:39:33.278
CHARLES LEISERSON: 是. 很好

498
00:39:33.300 --> 00:39:36.508
没错, 这是一点, 但还有一个东西我们利用的不是很号

499
00:39:37.053 --> 00:39:42.996
这是我们接下来要做的两点优化之一, 能让我们的代码变得非常快

500
00:39:43.304 --> 00:39:45.446
另一点是什么?请讲?

501
00:39:45.623 --> 00:39:48.934
听众: 混合乘加运算

502
00:39:51.980 --> 00:39:56.138
CHARLES LEISERSON: 这和之前的其实是同一方向

503
00:39:56.780 --> 00:40:02.492
还有一个完全不同的方向, 说?

504
00:40:02.833 --> 00:40:05.555
听众: 缓存命中率还有很大提升空间

505
00:40:05.620 --> 00:40:06.680
CHARLES LEISERSON: 对

506
00:40:06.680 --> 00:40:09.620
我们其实可以更高效的利用缓存

507
00:40:10.132 --> 00:40:13.315
所以让我们再回到硬件缓存上

508
00:40:13.337 --> 00:40:18.543
重新组织计算, 尽可能的重用缓存离得数据

509
00:40:18.682 --> 00:40:21.486
因为不命中缓存很慢, 命中缓存会很快

510
00:40:21.508 --> 00:40:25.594
尝试尽可能地利用已经在缓存中的数据

511
00:40:26.327 --> 00:40:32.973
让我们看一看, 假设我们要计算C的一整行

512
00:40:33.780 --> 00:40:41.704
所以计算C的一整行... 因为它是个4096长度的向量

513
00:40:41.793 --> 00:40:47.126
也就是我们需要4096次写操作

514
00:40:47.678 --> 00:40:55.622
我们能得到一些缓存局部性, 不过我们还是做了4096次写操作

515
00:40:55.964 --> 00:41:05.584
为了计算一整行, 我们需要读取4096次A

516
00:41:06.500 --> 00:41:18.838
以及B所有的元素, 因为我需要B的每一列来计算整行C

517
00:41:18.842 --> 00:41:21.580
明白吗?

518
00:41:22.137 --> 00:41:31.798
所以只是计算一行C, 我就需要一行A和所有B中元素

519
00:41:32.042 --> 00:41:43.281
因为C的第一个元素需要第一列B, C第二个需要B第二列

520
00:41:43.319 --> 00:41:48.072
如果你没有跟上, 不要担心, 我只是粗略过一下

521
00:41:48.110 --> 00:41:50.610
之后会更深层次的研究这些东西

522
00:41:50.610 --> 00:41:52.838
有很多时间掌握这些知识

523
00:41:52.849 --> 00:41:57.866
主要点在于, 你需要遍历矩阵B, 而且如果你想计算另一行C

524
00:41:58.008 --> 00:41:59.300
你需要重复整个流程

525
00:41:59.300 --> 00:42:04.254
遍历一行A, 然后遍历矩阵B所有元素

526
00:42:04.287 --> 00:42:10.035
总计大概1600万, 不, 1700万次访问

527
00:42:10.835 --> 00:42:17.907
这个次数可是相当多的, 所以, 假如我分块计算呢?

528
00:42:18.470 --> 00:42:25.011
如果我只计算C中一个64 x 64的部分, 而不是一整行C

529
00:42:25.530 --> 00:42:31.128
让我们看看会发生什么, 以及, 不要忘掉刚才1600, 1700万次的次数

530
00:42:31.515 --> 00:42:33.140
因为我们要做个比较

531
00:42:33.498 --> 00:42:35.127
所以分块计算如何?

532
00:42:35.138 --> 00:42:43.856
如果只关注一块64 x 64的方阵, 还是需要4096次写操作

533
00:42:44.987 --> 00:42:52.382
但现在我需要读取A矩阵64行, 大概20万次

534
00:42:53.400 --> 00:43:04.018
对于B, 我需要访问64列, 大概26万次

535
00:43:04.629 --> 00:43:09.014
总计只需要约50万次操作

536
00:43:09.803 --> 00:43:19.618
所以读写次数大大减少了, 可能这些东西就能放到缓存离了

537
00:43:20.796 --> 00:43:28.075
所以按块计算, 而不是按行计算, 同等大小的区域所需计算次数少多了

538
00:43:29.120 --> 00:43:32.976
效率得多, 这种技术叫做tiling(分块)

539
00:43:32.988 --> 00:43:41.602
所以如果分块进行矩阵乘法, 把矩阵划分成, 比如64 x 64的子矩阵

540
00:43:41.630 --> 00:43:45.530
然后像这样做两层的矩阵乘法

541
00:43:45.530 --> 00:43:51.946
外层使用相同的算法, 做子矩阵之间的计算, 而到了内层的时候

542
00:43:52.334 --> 00:44:00.934
也就是做64 x 64子矩阵的时候, 再跑一次三层循环

543
00:44:00.950 --> 00:44:08.157
所以总共是6层循环, 基本上就是这样划分的

544
00:44:08.157 --> 00:44:13.627
当然, 有一个调优参数, 就是每一块的大小

545
00:44:13.648 --> 00:44:16.682
你懂的, 就是子矩阵的大小到底该是多少?

546
00:44:16.689 --> 00:44:20.760
应该是64吗? 又或者128?

547
00:44:20.785 --> 00:44:28.833
到底该多大? 怎么找到最优的参数大小?

548
00:44:29.817 --> 00:44:31.487
有想法吗, 各位?

549
00:44:34.074 --> 00:44:37.108
听众: 你可以根据缓存大小估算

550
00:44:37.108 --> 00:44:38.650
CHARLES LEISERSON: 你的确可以这么做

551
00:44:38.650 --> 00:44:42.784
但你不知道其他的大小在处理器上表现如何

552
00:44:43.108 --> 00:44:44.685
听众: 全测一遍就好了

553
00:44:44.696 --> 00:44:47.116
CHARLES LEISERSON: 没错, 只要全测一遍就好了, 穷举法!

554
00:44:47.890 --> 00:44:50.438
试试看哪个参数结果最好

555
00:44:50.450 --> 00:44:56.451
结果表明, 大小为32时, 程序耗时最短

556
00:44:57.300 --> 00:44:58.990
只是针对这个问题来说

557
00:45:00.175 --> 00:45:11.097
所以你可以分块计算, 然后速度就变快了, 相对提升1.7倍

558
00:45:12.520 --> 00:45:19.724
我们现在大概... 几乎是峰值的10%

559
00:45:20.055 --> 00:45:28.486
如果你使用cachegrind, 或者别的什么工具, 你能看到总共有多少次缓存命中等等

560
00:45:28.497 --> 00:45:36.185
你能看到分块计算的未命中数要比整行计算少得多

561
00:45:37.130 --> 00:45:44.421
再强调一次, 你可以使用工具来观察到底发生了什么

562
00:45:45.063 --> 00:45:50.439
而且, 机器上并不只有一块缓存, 不只一个

563
00:45:50.454 --> 00:45:58.364
实际上有三级缓存, 有一级缓存, 数据和指令缓存

564
00:45:58.390 --> 00:46:01.261
我们考虑的是数据缓存, 矩阵的数据缓存

565
00:46:01.283 --> 00:46:07.158
也有二级缓存, 也是处理器独有的, 以及一个共享的三级缓存

566
00:46:07.185 --> 00:46:14.541
然后才是DRAM, 另外也可以访问邻近处理器的缓存等等

567
00:46:15.056 --> 00:46:17.908
这些缓存大小不一, 你可以看到缓存大小会逐渐增大

568
00:46:18.827 --> 00:46:27.493
从32KB到256KB, 25MB, 最后一级主存的60GB

569
00:46:27.922 --> 00:46:35.826
所以你还可以做多级分块, 然后就有两个调优参数s和t

570
00:46:36.593 --> 00:46:42.770
不过现在, 很可惜, 不能用二分查找来调优参数, 因为这是多维的

571
00:46:42.905 --> 00:46:52.673
你还是需要穷举, 如果多级分块的话, 你会得到... 九层循环

572
00:46:54.683 --> 00:47:00.204
虽然我肯定不想写这样的代码, 但机器有三级缓存, 对吗?

573
00:47:00.859 --> 00:47:05.299
有人能说出循环层数吗?

574
00:47:05.310 --> 00:47:09.285
三级缓存, 三级分块, 循环层数是多少?

575
00:47:13.527 --> 00:47:16.220
你就猜一猜是多少

576
00:47:16.220 --> 00:47:17.040
听众: 12层

577
00:47:17.040 --> 00:47:21.100
CHARLES LEISERSON: 12层, 没错, 你需要12层

578
00:47:21.314 --> 00:47:27.169
那真的是...  就和我说的一样, 优化会让代码变丑

579
00:47:27.960 --> 00:47:31.121
看的下巴都要掉下来了

580
00:47:33.975 --> 00:47:39.927
不过实际上有个技巧, 你可以以2次幂为准分块

581
00:47:39.941 --> 00:47:47.982
然后递归的, 同时解决子问题, 也就是分支法

582
00:47:47.988 --> 00:47:58.668
你划分出四个子矩阵, 然后观察得出, 需要解决8个大小减半的子问题

583
00:47:58.703 --> 00:48:02.228
然后把结果都加起来

584
00:48:03.146 --> 00:48:08.944
所以你得做八个n/2大小方阵乘法, 以及n大小的方阵加法

585
00:48:08.985 --> 00:48:13.803
然后你就得到结果, 不过你递归的解决了问题, 对吧

586
00:48:14.320 --> 00:48:19.934
而且性能应该类似, 这是示例代码

587
00:48:20.394 --> 00:48:25.740
我根本不指望你能看懂这个代码, 不过我们并行了代码

588
00:48:25.790 --> 00:48:28.620
因为总是有四次乘法可以同时进行

589
00:48:28.664 --> 00:48:36.371
cilk_spawn函数负责执行子程序, 也就是一个子问题

590
00:48:36.438 --> 00:48:41.759
然后你可以接着执行下一条语句

591
00:48:41.763 --> 00:48:44.450
再执行一个, 再执行一个, 最后是cilk_sync

592
00:48:44.450 --> 00:48:49.936
这行负责等待前一阶段的四个子程序执行完成

593
00:48:50.570 --> 00:48:53.467
之后我们会学习这个东西

594
00:48:53.478 --> 00:49:04.067
这种解法大约耗时93秒, 比之前的版本慢50倍

595
00:49:04.421 --> 00:49:08.474
我们缓存利用率更高了, 但是结果却

596
00:49:08.496 --> 00:49:14.558
你得明白, 性能调优都是有代价的

597
00:49:14.577 --> 00:49:16.436
你必须得机灵一点

598
00:49:17.044 --> 00:49:20.879
所以发生什么了? 为什么结果变差了?

599
00:49:20.991 --> 00:49:25.921
而且如果你观察缓存命中率, 其实比之前要好

600
00:49:25.940 --> 00:49:32.072
只有很少未命中, 大部分都命中缓存了, 但还是变慢了

601
00:49:32.076 --> 00:49:35.098
你们觉得是什么原因, 让我叫一个人回答...

602
00:49:35.765 --> 00:49:39.438
听众: 启动函数需要额外开销

603
00:49:39.438 --> 00:49:42.206
CHARLES LEISERSON: 对没错, 启动函数的额外开销

604
00:49:42.253 --> 00:49:47.040
尤其是最小块的地方, 这种额外开销很明显

605
00:49:47.683 --> 00:49:51.090
所以我们通过引入最小的基本情形(base case)解决

606
00:49:51.090 --> 00:49:54.904
之前的时候, 我们会分解问题, 直到n为1

607
00:49:54.926 --> 00:49:58.546
所以连一次简单乘法, 都有函数调用开销

608
00:49:58.815 --> 00:50:09.023
那么我们就选一个阈值, 低于阈值时, 直接使用一个标准/优秀算法计算

609
00:50:09.164 --> 00:50:14.401
高于阈值时, 我们就分而治之

610
00:50:14.423 --> 00:50:27.640
我们的基本情形, 就普通地做矩阵乘法

611
00:50:29.961 --> 00:50:36.005
又一次, 这个阈值是一个可以调节的参数

612
00:50:36.090 --> 00:50:43.513
这个情况, 我猜是64最好. 程序耗时1.95秒

613
00:50:43.835 --> 00:50:48.384
我没有做n为1时的情况, 因为那真的非常慢..

614
00:50:48.552 --> 00:50:49.950
听众: 应该是32

615
00:50:49.950 --> 00:50:52.949
CHARLES LEISERSON: 啊, 对不起, 是32, 32更好一点, 1.3秒

616
00:50:53.001 --> 00:50:56.980
非常好, 所以我们选32, 我应该高亮这一行的

617
00:50:58.980 --> 00:51:01.451
应该在演示上高亮它一下

618
00:51:01.472 --> 00:51:07.314
所以这样做, 我们得到了峰值的12%

619
00:51:08.330 --> 00:51:17.163
你可以看看缓存为命中的情况

620
00:51:17.399 --> 00:51:26.784
这是并行循环的L1缓存, 而分治未命中最少, 最低级缓存同样最少

621
00:51:27.706 --> 00:51:33.227
而总计缓存访问次数, 非常少, 所以分治法大获全胜

622
00:51:34.652 --> 00:51:42.777
之前还提过一点, 我们没有利用向量式硬件

623
00:51:42.985 --> 00:51:47.056
这些东西都可以直接操作向量

624
00:51:47.855 --> 00:51:55.323
向量处理硬件以SIMD形式, 运算向量, 也就是单指令多数据形式

625
00:51:55.342 --> 00:51:59.467
也就是你只给一条指令, 但它却会运算以整个向量

626
00:52:00.747 --> 00:52:13.294
我说过, 机器每核有八个浮点运算单位, 而且还能乘加融合

627
00:52:14.299 --> 00:52:22.972
所以每个向量寄存器都有多个字, 我们机器上应该是4字

628
00:52:23.593 --> 00:52:25.198
我觉得应该是

629
00:52:29.792 --> 00:52:34.893
但你不能不管三七二十一直接使用指令

630
00:52:35.543 --> 00:52:44.474
你需要把.... 把所有这些数据当成同一块

631
00:52:44.496 --> 00:52:51.925
你不能让整条线上的这个向量单元这么做, 另一个那样做

632
00:52:51.950 --> 00:52:56.755
他们做的事情必须完全一样, 除了访问的内存位置不同

633
00:52:57.944 --> 00:53:03.638
如果你这么做, 其实.... 额

634
00:53:03.731 --> 00:53:12.760
其实我们已经在利用这一点, 你可以要求编译器返回一个向量化报告

635
00:53:12.791 --> 00:53:19.994
它会打印出什么东西向量化了, 什么没有

636
00:53:20.022 --> 00:53:24.268
之后我们会教授如何向量化编译器没有自动向量化的代码

637
00:53:24.781 --> 00:53:28.983
尤其是, 很多机器其实支持最新的向量指令集

638
00:53:28.989 --> 00:53:33.518
所以编译器对自动向量化的态度比较保守

639
00:53:33.529 --> 00:53:39.516
如果你是为某一台机器专门编译代码, 你可以..

640
00:53:39.531 --> 00:53:41.771
这是其中一些专门的向量化编译器参数

641
00:53:41.815 --> 00:53:47.171
如果机器支持AVX指令集, 你就可以用AVX, 或者AVX2

642
00:53:47.324 --> 00:53:50.415
你可以使用乘加混合指令集

643
00:53:50.477 --> 00:53:55.045
你可以给编译器一个字符串, 告诉它你机器的处理器架构

644
00:53:55.053 --> 00:54:03.265
也可以命令编译器, 这台机器支持什么指令, 你就编译什么指令, 不管它什么架构

645
00:54:04.217 --> 00:54:10.843
不过, 浮点数其实有些大问题

646
00:54:10.850 --> 00:54:16.150
比如不满足交换律, 你做A乘以B乘以C

647
00:54:16.226 --> 00:54:20.600
你括号加的位置不同, 结果可能也会不同

648
00:54:21.411 --> 00:54:30.627
所以你写了一段这样的代码, 编译器一般不会交换顺序

649
00:54:30.708 --> 00:54:34.271
因为编译器优化一般要保证结果完全一致

650
00:54:34.348 --> 00:54:38.620
不过你可以传一个叫做fast math的参数, -ffast-math

651
00:54:38.654 --> 00:54:41.390
允许编译器做一些运算重排等等

652
00:54:41.990 --> 00:54:45.985
如果重排顺序用处不大, 它可能会保持原样

653
00:54:46.595 --> 00:54:58.602
如果你使用fast math, 并指定native架构, 编译器向量化直接提升性能两倍

654
00:55:01.251 --> 00:55:04.295
有什么问题吗?

655
00:55:04.295 --> 00:55:11.125
听众: 我们矩阵的数据类型是32位的吗?

656
00:55:11.125 --> 00:55:13.190
CHARLES LEISERSON: 是64位的

657
00:55:14.910 --> 00:55:19.723
64位现在挺常见的, 虽然叫做双精度, 但已经是标准了

658
00:55:19.730 --> 00:55:26.466
除非你做一些AI应用, 那你可能想要低精度浮点

659
00:55:26.520 --> 00:55:29.330
听众: 所以float和double位数一样?

660
00:55:29.330 --> 00:55:32.690
CHARLES LEISERSON: 不, float是32位的

661
00:55:32.690 --> 00:55:42.955
一般来说, 人们用64位精度来有精度要求的线性代数计算

662
00:55:43.012 --> 00:55:48.643
但有些时候可以使用低精度, 然后性能就会提升

663
00:55:48.655 --> 00:55:53.971
如果你发现你可以使用低精度的话, 之后会讲这个

664
00:55:55.618 --> 00:56:05.757
所以最后一个优化是, 我们其实可以手动调用向量化指令, 而不是依赖编译器

665
00:56:05.865 --> 00:56:16.534
其实有一整本手册都是关于这些可以C语言调用的指令

666
00:56:16.569 --> 00:56:22.418
你应该知道你到底想用哪些向量指令, 就不必让编译器去猜了

667
00:56:24.821 --> 00:56:31.580
你也可以做些其他角度的优化, 比如

668
00:56:31.580 --> 00:56:37.778
你可以做预处理, 或者转置矩阵(真的有用), 或者数据对齐

669
00:56:37.781 --> 00:56:42.704
还有许多更聪明的最小问题(base case)的优化算法

670
00:56:46.522 --> 00:56:52.517
所以流程就是调优, 思考, 写代码, 然后做许多不同的测试

671
00:56:52.524 --> 00:57:00.689
这里就能体现云服务器的好处, 因为你不必在自己电脑上浪费时间

672
00:57:01.593 --> 00:57:04.010
你懂, 就是在跑测试时, 只能发呆或者干什么别的

673
00:57:04.010 --> 00:57:09.244
比如你想跑十个测试, 可以直接用十台服务器, 然后同时启动

674
00:57:09.344 --> 00:57:18.703
这样做, 也就是应用AVX指令集, 我们得到0.41

675
00:57:19.970 --> 00:57:27.460
也就是峰值的41%, 5万倍的绝对性能提升

676
00:57:28.209 --> 00:57:32.820
我们优化就做到这儿了

677
00:57:33.416 --> 00:57:42.595
因为现在我们已经比Intel专业的MKL库还要快了

678
00:57:44.275 --> 00:57:47.350
值得思考的是, 为什么我们跑不到峰值, 为什么不能利用所有资源?

679
00:57:47.355 --> 00:57:57.574
而我邀请你来和我一起探索这个问题

680
00:57:57.585 --> 00:58:02.817
其实Intel的MKL其实比我们做的要好, 因为我们假设n是2次幂

681
00:58:02.826 --> 00:58:08.115
Intel没有这么假设, 他们的程序更健壮

682
00:58:08.124 --> 00:58:22.006
尽管我们在4096方阵上胜出, 但不一定也在别的大小上胜出

683
00:58:23.981 --> 00:58:31.433
不过重要的是, 我们做了什么? 5万倍的性能提升

684
00:58:32.270 --> 00:58:45.195
如果你类比汽油能效, 每加仑多少里, 这就像是我们坐上了喷气飞机

685
00:58:45.696 --> 00:58:53.922
你可以用一台小黄蜂追上喷气飞机, 不管是什么小黄蜂

686
00:58:54.565 --> 00:58:56.924
这就是今天我们做到的事情

687
00:58:56.935 --> 00:59:03.755
不过别怪我没提醒你, 你不大可能见到像矩阵计算这样大的性能提升

688
00:59:04.520 --> 00:59:10.093
因为矩阵计算是个很好的例子, 它的情况极其理想

689
00:59:10.997 --> 00:59:14.237
不过我们还是能看到一些实质提升的

690
00:59:14.259 --> 00:59:19.753
在6.172, 你会学到如何印发性能这种货币

691
00:59:19.790 --> 00:59:24.438
全靠你自己来实现, 而不是别的什么库

692
00:59:24.481 --> 00:59:28.194
以免出现"额, 我不擅长优化这个"这种局面

693
00:59:28.194 --> 00:59:33.045
还有一件事, 这门课的重点是多核运算

694
00:59:33.066 --> 00:59:40.131
我们不会专门面向GPU, 文件系统, 或者网络性能调优

695
00:59:40.149 --> 00:59:48.602
现实世界中那很重要, 但我们还是从某个特定领域学习比较简单

696
00:59:48.607 --> 01:00:01.645
这个特定领域就是多核计算, 学懂这个学其他的就很容易了

697
01:00:01.670 --> 01:00:03.344
而且也会很擅长其他的东西

698
01:00:03.356 --> 01:00:07.794
你们学得是某种核心的, 最根本的基础

699
01:00:07.795 --> 01:00:20.007
翻译&校对&时轴: xhe
Github: xhebox/mit6172_cn